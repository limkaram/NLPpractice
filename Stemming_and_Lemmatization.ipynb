{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stemming_and_Lemmatization.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6w3r8FY7OlB7lqjB3/pxH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limkaram/Natural_language_processing_with_deep_learning/blob/main/Stemming_and_Lemmatization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDWoxeS0s4Pn"
      },
      "source": [
        "## 1. 표제어 추출(Lemmatization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7beJ2x2vs5iP"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
        "\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "\n",
        "       if treebank_tag.startswith('J'):\n",
        "           return wordnet.ADJ\n",
        "       elif treebank_tag.startswith('V'):\n",
        "           return wordnet.VERB\n",
        "       elif treebank_tag.startswith('N'):\n",
        "           return wordnet.NOUN\n",
        "       elif treebank_tag.startswith('R'):\n",
        "           return wordnet.ADV\n",
        "       else:\n",
        "           return None # for easy if-statement \n",
        "\n",
        "for word, tag in pos_tag(words):\n",
        "    wordnet_tags = get_wordnet_pos(tag)\n",
        "    if wordnet_tags is None:\n",
        "        lemma = lemmatizer.lemmatize(word)\n",
        "    else:\n",
        "        lemma = lemmatizer.lemmatize(word, pos=wordnet_tags)\n",
        "    print(lemma, wordnet_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYQcrJVc1JzU"
      },
      "source": [
        "* WordNetLemmatizer : nltk 표제어 추출 지원 모듈\n",
        "* 표제어 추출은 단어의 어간 즉, 단어의 의미를 담고 있는 단어의 핵심 부분을 추출해 주는 것을 의미\n",
        "* 표제어 추출시 단어 품사와 함께 전달해야 본연의 표제어 추출이 원활히 가능\n",
        "* 표제어 추출시 nltk의 pos_tag를 그대로 활용하면, lemmatizer의 tag와 매칭이 안되어서 활용이 불가함\n",
        "    - ex. 명사인 경우 nltk tag : 'NN' / lemmatizer 지원 tag : 'n'\n",
        "* 주로 표준인 Penn Treebank pos tag의 기준으로 통일 시키게 됨(from nltk.corpus import wordnet)\n",
        "* wordnet은 영어 어휘 데이터베이스라고 보면됨\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuoS5PiI2Pyi"
      },
      "source": [
        "## 2. 어간 추출(Stemming)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaOn1Id92eS2"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "text = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\"\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)\n",
        "\n",
        "stemmed_words = [stemmer.stem(token) for token in tokens]\n",
        "print(stemmed_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkBYAHPv-9N0"
      },
      "source": [
        "* 어간 추출은 표제어 추출과 다르게 단순 규칙 기반의 Poter Algorithm에 의해서 진행이 된다.\n",
        "따라서 pos tag를 주지 않아도 된다.\n",
        "* 단순 규칙 기반 동작이기 때문에 존재하지 않는 단어로 반환해 주기도 한다.\n",
        "* 표제어 추출보다 일반적으로 빠르고, PorterStemmer는 정밀하게 설계되어 정확도가 높으므로 영어 자연어 처리에서 어간추출시 준수한 선택이다.\n"
      ]
    }
  ]
}