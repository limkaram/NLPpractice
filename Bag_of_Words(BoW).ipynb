{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bag_of_Words(BoW).ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZzeTTrXfkNOYa8ieSMJg7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limkaram/Natural_language_processing_with_deep_learning/blob/main/Bag_of_Words(BoW).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_9m39gB-sn3"
      },
      "source": [
        "## Bag Of Words(BoW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6lvdxaf-2Do"
      },
      "source": [
        "* 가방안에 단어들을 넣어 섞는 개념\n",
        "* 단어들의 순서를 고려치 않고, 단어의 개수가 중요한 영향 요소가 됨\n",
        "* BoW를 만드는 과정\n",
        "    - 각 단어에 고유한 Integer Encoding 진행\n",
        "    - 각 인덱스의 위치에 단어 토큰의 등장 획수를 기록한 벡터 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFJP60KP_JxD"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92PAndAjDmAB"
      },
      "source": [
        "1. 직접 BoW 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sbend0iU_jWk"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "import re\n",
        "\n",
        "okt = Okt()\n",
        "\n",
        "text = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
        "\n",
        "# regex 활용 온점 제거\n",
        "token = re.sub('\\.', '', text)\n",
        "print(token)\n",
        "\n",
        "token = okt.morphs(token)\n",
        "print(token)\n",
        "\n",
        "word2index = {}\n",
        "bow = []\n",
        "\n",
        "for voca in token:\n",
        "    if voca not in word2index:\n",
        "        word2index[voca] = len(word2index)\n",
        "        bow.insert(len(word2index), 1)\n",
        "    else:\n",
        "        idx = word2index[voca]\n",
        "        bow[idx] += 1\n",
        "print(word2index)\n",
        "print(bow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVoBFBPKDpRC"
      },
      "source": [
        "2. 사이킷 런 CountVectorizer 활용 BoW 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6n0OImZDvfl"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = ['you know I want your love. because I love you.']\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray())  # 코퍼스로부터 각 단어의 빈도수를 기록\n",
        "print(vector.vocabulary_)  # 각 단어의 인덱스가 어떻게 부여되었는지를 보여 줌"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIga2CRqESGN"
      },
      "source": [
        "* CountVectorizer는 BoW를 만들 때 기본적으로 단어의 길이가 2이상인 문자에 대해서만 토큰으로 인식\n",
        "* CountVectorizer는 띄어쓰기만을 기준으로 단어를 자르는 낮은 수준의 토큰화를 진행하여 BoW를 만듬\n",
        "* 한국어에는 조사 등의 이유로 제대로 BoW가 만들어지지 않음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOBq_KzDE-hW"
      },
      "source": [
        "2-1. 불용어 제어 BoW 만들기(사용자 직접 정의한 불용어)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0WOb3mKFIr9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "vector = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
        "print(vector.fit_transform(text).toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb4pTxHnFcbT"
      },
      "source": [
        "2-2. CountVectorizer에서 제공하는 자체 불용어 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eI-3nkUHFf07"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "vector = CountVectorizer(stop_words='english')\n",
        "print(vector.fit_transform(text).toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CnmRH2kFuvt"
      },
      "source": [
        "2-3. NLTK에서 지원하는 불용어 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bubKJDs_FwYB"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "text = [\"Family is not an important thing. It's everything.\"]\n",
        "stop_words = stopwords.words('english')\n",
        "vector = CountVectorizer(stop_words=stop_words)\n",
        "print(vector.fit_transform(text).toarray())\n",
        "print(vector.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}