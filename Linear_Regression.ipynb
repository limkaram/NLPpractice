{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear_Regression.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOuWaxrEYij1id/F9wMzDd+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limkaram/Natural_language_processing_with_deep_learning/blob/main/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6vrCrZe4YPA"
      },
      "source": [
        "## 선형 회귀(Linear Regression)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOaR5aJv4b-y"
      },
      "source": [
        "* 선형회귀는 predicsion을 할 때 활용되는 머신러닝 모델\n",
        "* optimizer는 비용 함수를 최소화하는 매개변수인 W, b를 찾기 위한 작업을 수행해주는 알고리즘을 의미\n",
        "* 즉 실제 W, b의 값을 MSE(Mean Squared Error) + Gradient Descent를 활용하여 최적화하는 최적화 알고리즘을 의미함\n",
        "* MSE는 각 Feature들의 예측 값과 정답간의 오차를 전부 모아서 평균을 낸 것을 의미(제곱을 하는 이유는 오차의 값이 양수 혹은 음수가 나올 수 있어 전체를 절대 값으로 맞춰주는 것)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHuHB8Lg4hT_"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np\n",
        "\n",
        "X=np.array([1,2,3,4,5,6,7,8,9]) # 공부하는 시간\n",
        "y=np.array([11,22,33,44,53,66,77,87,95]) # 각 공부하는 시간에 맵핑되는 성적\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=1, activation='linear'))\n",
        "sgd = optimizers.SGD(lr=0.01)\n",
        "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
        "model.fit(X, y, batch_size=1, epochs=300, shuffle=False)  # 주어진 X, y에 대해서 오차를 최소화하는 작업을 300번 시도"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DHOVdyf6jXE"
      },
      "source": [
        "* SGD는 경사 하강법(Gradient Descent)를 의미\n",
        "* lr : learning rate로 학습률을 의미하고, gradient descent에서 얼마나 많이 W을 변화 시키며, 기울기가 0인 지점을 찾아갈지를 결정함\n",
        "* loss : 손실 함수를 결정하는 요소, 여기서는 'mse'를 활용\n",
        "* activation : 활성화 함수를 결정하는 요소로 선형 회귀시 'linear' 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8ilyldC74b2"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(X, model.predict(X), 'b', X, y, 'k.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s95JDebD9g89"
      },
      "source": [
        "print(model.predict([9.5]))  # 9.5시강 공부했을 때 예측하는 점수를 보여줌"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}