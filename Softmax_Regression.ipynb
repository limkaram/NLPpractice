{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Softmax_Regression.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOfvDFDNduLaoa4scVanQ0K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limkaram/Natural_language_processing_with_deep_learning/blob/main/Softmax_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jdSEfRUjjfN"
      },
      "source": [
        "## Softmax Regression(소프트맥스 회귀)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd3WVZlAjo4y"
      },
      "source": [
        "* 소프트맥스 회귀는 Binary Classification이 아닌 Multi-class Classification을 위한 알고리즘\n",
        "* Gradient Descent를 통해 Optimizing하는 것은 동일\n",
        "* 활성화 함수로 'softmax'를 활용(본 실습에서는 경사하강법의 일종인 adam 활용\n",
        "* 출력층의 비용함수는 이진 분류('binary clossentropy')와 다르게 'categorical_crossentropy'를 활용\n",
        "* 실제 정답에 해당하는 값은 Ont-hot Encoding을 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb3iHjfHlI2V"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(r'/content/dirve/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbS498FMke4u"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "data = pd.read_csv('/content/dirve/My Drive/Natural_language_processing_with_deep_learning/iris.csv', encoding='latin1')  # data load\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df4TY_mhmajY"
      },
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='ticks', color_codes=True)\n",
        "g = sns.pairplot(data, hue='Species', palette='husl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li0zbAevnSY-"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "data['Species'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPRMRaegq4-6"
      },
      "source": [
        "# Integer Encoding 진행\n",
        "data['Species'] = data['Species'].replace(['setosa', 'versicolor', 'virginica'], [0, 1, 2])  # ['setosa' 'versicolor' 'virginica'] -> [0, 1, 2]\n",
        "data['Species'].value_counts().plot(kind='bar')  # 정수 인코딩 결과 확인"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_n5I9a9reUh"
      },
      "source": [
        "# Train data와 Test data 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_X = data[['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']].values\n",
        "data_y = data['Species'].values\n",
        "data_y[:10]\n",
        "\n",
        "(X_train, X_test, y_train, y_test) = train_test_split(data_X, data_y, train_size=0.8, random_state=1234)\n",
        "# 훈련 데이터와 테스트 데이터를 8:2로 나눕니다. 또한 데이터의 순서를 섞습니다.\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "# 훈련 데이터와 테스트 데이터에 대해서 원-핫 인코딩\n",
        "\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLLFZnB2tNj6"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(3, input_dim=4, activation='softmax'))\n",
        "sgd = optimizers.SGD(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, batch_size=1, epochs=200, validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kG0Vc-C7IHAG"
      },
      "source": [
        "epochs = range(1, len(history.history['accuracy']) + 1)\n",
        "plt.plot(epochs, history.history['loss'])\n",
        "plt.plot(epochs, history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edFOI_eeI1yy"
      },
      "source": [
        "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}