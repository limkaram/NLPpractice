{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "tensorflow2.0",
      "language": "python",
      "name": "tensorflow"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Recurrent_Neural_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limkaram/Natural_language_processing_with_deep_learning/blob/main/Recurrent_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okmHb6PlwCyt"
      },
      "source": [
        "## RNN(Recurrent_Neural_Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hiUuxlWwCyt"
      },
      "source": [
        "* model.add(SimpleRNN(hidden_size, input_shape=(timesteps, input_dim))) \n",
        "* hidden_size = 은닉 상태의 크기를 정의. 메모리 셀이 다음 시점의 메모리 셀과 출력층으로 보내는 값의 크기(output_dim)와도 동일\n",
        "    - 중소형 모델의 경우 보통 128, 256, 512, 1024 등의 값을 가짐\n",
        "* timesteps = 입력 시퀀스의 길이(input_length). 시점의 수\n",
        "* input_dim = 입력의 크기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh5vwewSwCyt"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TqNAh5HOwCyu",
        "outputId": "975d525e-9d83-4281-c138-a9beeabae127"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, input_shape=(2, 10)))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 3)                 42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnRLtrVywCyw"
      },
      "source": [
        "* RNN 층은 (batch_size, timesteps, input_dim) 크기의 3D 텐서를 입력으로 받음\n",
        "* RNN 층은 사용자의 설정에 따라 두 가지 종류의 출력을 내보냄\n",
        "    - 메모리 셀의 최종 시점의 은닉 상태만을 리턴하고자 한다면 (batch_size, output_dim) 크기의 2D 텐서를 리턴\n",
        "    - 메모리 셀의 각 시점(time step)의 은닉 상태값들을 모아서 전체 시퀀스를 리턴하고자 한다면 (batch_size, timesteps, output_dim) 크기의 3D 텐서를 리턴\n",
        "    - 이 차이는 인자인 return_sequences=True or False에 따라서 달라짐\n",
        "    - 마지막 은닉 상태만 전달하도록 하면 many-to-one 문제를 풀 수 있고, 모든 시점의 은닉 상태를 전달하도록 하면, 다음층에 은닉층이 하나 더 있는 경우이거나 many-to-many 문제를 풀 수 있음\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6qmKnj3wCyw",
        "outputId": "74108b05-40db-43b2-94b3-d683fe21feae"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, batch_input_shape=(8,2,10)))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_2 (SimpleRNN)     (8, 3)                    42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w754iIuuwCyw"
      },
      "source": [
        "* batch_size를 8로 하게되면, 출력의 크기가 (8, 3)이 됨. 즉, 2D 텐서가 반환됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eZLF4r2wCyw",
        "outputId": "f982920d-4686-458a-9c12-6efc5d858b09"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(SimpleRNN(3, batch_input_shape=(8,2,10), return_sequences=True))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn_4 (SimpleRNN)     (8, 2, 3)                 42        \n",
            "=================================================================\n",
            "Total params: 42\n",
            "Trainable params: 42\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZXGwkpNwCyw"
      },
      "source": [
        "* batch_size를 8로 하게되면, 출력의 크기가 (8, 2, 3)인 3D 텐서가 됨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugWftuAzRxUp"
      },
      "source": [
        "## numpy만으로 RNN 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znkAwRH8RuP3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 10  # 문장 토큰의 수\n",
        "input_dim = 4  # 토큰을 표현한 벡터의 차원\n",
        "hidden_size = 8  # 기억하려는 메모리 셀의 용량\n",
        "\n",
        "inputs = np.random.random((timesteps, input_dim))\n",
        "hidden_state_t = np.zeros((hidden_size, ))  # 최초 h(t) 0으로 초기화"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC6vNr4UTQe-"
      },
      "source": [
        "Wx = np.random.random((hidden_size, input_dim))\n",
        "Wh = np.random.random((hidden_size, hidden_size))\n",
        "b = np.random.random((hidden_size, ))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te1bF9hqZFUU",
        "outputId": "a1684620-b3b3-438b-8ed5-d43f035e474a"
      },
      "source": [
        "total_hidden_states = []\n",
        "for input in inputs:\n",
        "    output_t = np.tanh(np.dot(Wx, input) + np.dot(Wh, hidden_state_t) + b)\n",
        "    total_hidden_states.append(output_t)\n",
        "    hidden_state_t = output_t\n",
        "\n",
        "total_hidden_states = np.stack(total_hidden_states, axis=0)\n",
        "print(total_hidden_states)\n",
        "print(total_hidden_states.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9974348  0.9997869  0.99999217 0.99988961 0.99997305 0.99999263\n",
            "  0.99999011 0.99997781]\n",
            " [0.99655602 0.99948838 0.99998617 0.99976661 0.99996847 0.99998959\n",
            "  0.99998342 0.9999474 ]\n",
            " [0.99783981 0.99981979 0.99999387 0.9998945  0.99997323 0.99999331\n",
            "  0.99999374 0.99998231]\n",
            " [0.99856032 0.99940091 0.99998179 0.9998905  0.99998039 0.99999498\n",
            "  0.99997187 0.99987017]\n",
            " [0.99863353 0.99964178 0.99998336 0.99990744 0.99998683 0.99999583\n",
            "  0.99997711 0.99991424]\n",
            " [0.99845495 0.99975476 0.99998904 0.99992362 0.99998294 0.99999537\n",
            "  0.99998425 0.99995563]\n",
            " [0.99892769 0.99961984 0.9999903  0.99993896 0.99997409 0.99999577\n",
            "  0.99998412 0.99992973]\n",
            " [0.99889888 0.99983731 0.99999232 0.99991534 0.99998773 0.9999964\n",
            "  0.99999418 0.99997148]\n",
            " [0.99833464 0.99984276 0.99999279 0.99991777 0.99998234 0.99999508\n",
            "  0.9999924  0.99997852]\n",
            " [0.99820375 0.99986755 0.99999252 0.99988569 0.99998706 0.99999507\n",
            "  0.99999453 0.99998224]]\n",
            "(10, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enMMfKlabS4P"
      },
      "source": [
        "## keras API 활용 DRNN(Deep RNN) 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8QEb1CfbZxA"
      },
      "source": [
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(hidden_size, return_sequences=True))\n",
        "model.add(SimpleRNN(hidden_size, return_sequences=True))  # many-to-many 아키텍처의 경우"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpD-yTiQdyrr"
      },
      "source": [
        "## BiRNN(Bidirectional RNN) 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_5_QCE9dyC5"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True), input_shape=(timesteps, input_dim)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T73PVwbRd6mY"
      },
      "source": [
        "DBiRNN(Deep Bidirectional RNN) 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssgylsrsd-W-"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True), input_shape=(timesteps, input_dim)))\n",
        "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True)))\n",
        "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True)))\n",
        "model.add(Bidirectional(SimpleRNN(hidden_size, return_sequences = True)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}